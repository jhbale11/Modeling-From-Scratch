{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0b8674-1d82-432d-8bcb-28f646c24d2c",
   "metadata": {},
   "source": [
    "# Resnet from Scratch\n",
    "\n",
    "Last Update : 2022/11/15\n",
    "\n",
    "Author : [jhbale11](https://github.com/jhbale11)\n",
    "\n",
    "--------------------------------------------------\n",
    "\n",
    "ResNet은 Skip Connection의 개념을 최초로 제시하였습니다. 이를 통해 Gradient Vanishing 문제를 걱정하지 않고 더 깊은 네트워크를 만들 수 있게 되었습니다. ResNet은 정확성 측면에서 비슷한 시기에 제시된 여러 모델들을 아웃퍼폼하였으며, 그에 대한 논문은 아래와 같습니다.\n",
    "\n",
    "- [paper](https://arxiv.org/pdf/1512.03385v1.pdf)\n",
    "\n",
    "\n",
    "### ResNet Architectures\n",
    "![](https://debuggercafe.com/wp-content/uploads/2022/08/resnet-models-from-table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328815b7-40e8-45c7-93ec-ecd821bffd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import Type\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235dc840-f14f-43d9-9eca-910b129fc900",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "![](https://debuggercafe.com/wp-content/uploads/2022/08/resnet18-basic-blocks-1.png)\n",
    "\n",
    "## Modeling Procedure\n",
    "\n",
    "ResNet18(다른 ResNet 변형들도 마찬가지)의 경우 4가지 다른 유형의 기본 블록이 있습니다. 면밀히 살펴보자면, 기본 블록(conv2_x에서 conv5_x로)에서 발생하는 유일한 변경 사항은 입력 및 출력 채널 수입니다. 그렇기에 이러한 블록을 여러 번 정의할 필요는 없습니다. 우리는 우리가 구현하는 논리에 따라 모든 것을 처리할 하나의 간단한 파이썬 클래스를 정의할 수 있습니다.\n",
    "\n",
    "각 블록 옆의 숫자는 Neural Network를 구축하는 동안 기본 블록을 반복해야 하는 횟수를 나타냅니다. ResNet18의 모든 기본 블록에 대해 아래와 같습니다.\n",
    "\n",
    "즉, 각 conv2_x에서 conv5_x에는 두 개의 기본 블록이 차례로 적층되어 있습니다. conv2_x를 conv5_x로 레이어 1을 레이어 4로 호출해보겠습니다.\n",
    "\n",
    "conv2_x => layer1\n",
    "conv3_x => layer2\n",
    "conv4_x => layer3\n",
    "conv5_x => layer4\n",
    "\n",
    "이를 바탕으로 layer 1을 시각화하면 아래와 같습니다.\n",
    "\n",
    "```bash\n",
    "(layer1): Sequential(\n",
    "    (0): BasicBlock(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "    (1): BasicBlock(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (relu): ReLU(inplace=True)\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3b0bd0-2d51-4fe4-91d1-0ede77cbee8e",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "## Create the Network\n",
    "\n",
    "Forward 함수에서 가장 먼저 발견하는 것은 Identity Variable입니다. 이 변수는 기본 블록으로 전달되는 원래 텐서 (x)의 복사본을 저장합니다. 그런 다음 이전 레이어의 출려과 함께 저장해둔 Identity Tensor를 추가합니다.\n",
    "\n",
    "이렇게 몇개의 레이어를 건너뛰고 Identity Tensor와 함께 계산해주는 과정에서 ResNet의 유명한 Skip Connection이 발생하게 됩니다.\n",
    "\n",
    "전반적인 Forward Algorithm은 아래와 같습니다.\n",
    "\n",
    "### Forward Algorithms\n",
    "![](https://debuggercafe.com/wp-content/uploads/2022/08/resnet-residual-block-for-resnet18-from-scratch-using-pytorch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc62431-f9b7-437b-ab07-f7a0dc21bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        stride: int = 1,\n",
    "        expansion: int = 1,\n",
    "        downsample: nn.Module = None\n",
    "    ) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        # Multiplicative factor for the subsequent conv2d layer's output channels.\n",
    "        # It is 1 for ResNet18 and ResNet34.\n",
    "        self.expansion = expansion\n",
    "        self.downsample = downsample\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size=3, \n",
    "            stride=stride, \n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            out_channels, \n",
    "            out_channels*self.expansion, \n",
    "            kernel_size=3, \n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92793517-a15a-4690-a9ca-da9bca10af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        img_channels: int,\n",
    "        num_layers: int,\n",
    "        block: Type[BasicBlock],\n",
    "        num_classes: int  = 1000\n",
    "    ) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if num_layers == 18:\n",
    "            # The following `layers` list defines the number of `BasicBlock` \n",
    "            # to use to build the network and how many basic blocks to stack\n",
    "            # together.\n",
    "            layers = [2, 2, 2, 2]\n",
    "            self.expansion = 1\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        # All ResNets (18 to 152) contain a Conv2d => BN => ReLU for the first\n",
    "        # three layers. Here, kernel size is 7.\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=img_channels,\n",
    "            out_channels=self.in_channels,\n",
    "            kernel_size=7, \n",
    "            stride=2,\n",
    "            padding=3,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
    "    def _make_layer(\n",
    "        self, \n",
    "        block: Type[BasicBlock],\n",
    "        out_channels: int,\n",
    "        blocks: int,\n",
    "        stride: int = 1\n",
    "    ) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        if stride != 1:\n",
    "            \"\"\"\n",
    "            This should pass from `layer2` to `layer4` or \n",
    "            when building ResNets50 and above. Section 3.3 of the paper\n",
    "            Deep Residual Learning for Image Recognition\n",
    "            (https://arxiv.org/pdf/1512.03385v1.pdf).\n",
    "            \"\"\"\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels, \n",
    "                    out_channels*self.expansion,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False \n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels * self.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
    "            )\n",
    "        )\n",
    "        self.in_channels = out_channels * self.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(\n",
    "                self.in_channels,\n",
    "                out_channels,\n",
    "                expansion=self.expansion\n",
    "            ))\n",
    "        return nn.Sequential(*layers)\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # The spatial dimension of the final layer's feature \n",
    "        # map should be (7, 7) for all ResNets.\n",
    "        print('Dimensions of the last convolutional feature map: ', x.shape)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7113902-56bf-4a31-8dd4-9e0935ddea0e",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "## Test the Implemented Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b76f2e87-0d54-493d-92c7-a52034322741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "11,689,512 total parameters.\n",
      "11,689,512 training parameters.\n",
      "Dimensions of the last convolutional feature map:  torch.Size([1, 512, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand([1, 3, 224, 224])\n",
    "model = ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=1000)\n",
    "print(model)\n",
    "\n",
    "# Total parameters and trainable parameters.\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"{total_trainable_params:,} training parameters.\")\n",
    "output = model(tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
